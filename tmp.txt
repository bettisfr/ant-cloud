# # Load the TFLite model
# model_path = "model.tflite"
# interpreter = tf.lite.Interpreter(model_path=model_path)
# interpreter.allocate_tensors()
#
# # Get input details
# input_details = interpreter.get_input_details()
# input_shape = input_details[0]['shape']  # Typically [1, height, width, channels]
# input_dtype = input_details[0]['dtype']  # Data type of the input tensor
# input_size = (input_shape[1], input_shape[2])  # (height, width)

def preprocess_image(image_path, input_size, input_dtype):
    image = np.array(Image.open(image_path).convert("RGB"))
    image = np.resize(image, (input_size[0], input_size[1], 3))
    if input_dtype == np.uint8:
        image = image.astype(np.uint8)
    else:
        image = image.astype(np.float32) / 255.0
    return np.expand_dims(image, axis=0)


# def predict(interpreter, input_data):
#     interpreter.set_tensor(input_details[0]['index'], input_data)
#     interpreter.invoke()
#     output_data = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])
#     return output_data


# def activate_b():
#     global count_b, count_a
#     led_red.value = 1
#     count_b += 1
#
#     # Run the ML model on the last captured image
#     if count_a > 0:  # Ensure there's at least one image captured
#         image_path = f"img/photo_{count_a}.jpg"
#         print(f"Running ML model on {image_path}...")
#         input_data = preprocess_image(image_path, input_size, input_dtype)
#         predictions = predict(interpreter, input_data)
#         print("Predictions:", predictions)
#     else:
#         print("No image available to process.")
#
#     led_red.value = 0